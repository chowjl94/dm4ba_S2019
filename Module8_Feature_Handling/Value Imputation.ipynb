{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "%matplotlib inline\n",
    "# sns.set(style='ticks', palette='Set2')\n",
    "plt.rcParams['figure.figsize'] = 15, 12\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv( \"data/train_mail.tsv\", sep='\\t' )\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's get a sense of the missing values\n",
    "\n",
    "**Question:** How many instances (rows) have _at least one_ missing value?\n",
    "\n",
    "**Question:** How are the missing values distributed among the features themselves?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following line will return how many null values (i.e. how man rows) we have for each feature\n",
    "\n",
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values for each case here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_fractions = 100.0 * (train_df.isnull().sum() / len(train_df))\n",
    "empty_fractions.sort_values(ascending=True).plot(kind=\"barh\", figsize=(10,8))\n",
    "\n",
    "average_overall = empty_fractions.mean()\n",
    "plt.axvline(x=average_overall, color='red')  # Plots a vertical line at x = <value>\n",
    "plt.text(average_overall - 1.5, -2, 'average\\nmissing', rotation=90)  # Set the text for the tick\n",
    "\n",
    "plt.title(\"Fraction of Instances with Missing Values per Feature\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 1: Drop the instances\n",
    "\n",
    "This approach is also commonly known as _listwise deletion_. We **remove** an instance _entirely_ if it contains even a single missing value.\n",
    "\n",
    "Despite some statistical advantages under certain assumptions* (e.g., avoiding bias), listwise deletion reduces the effective sample size of the population, since we are removing entire instances from the population. This may also detract from the predictive power of our models, and their ability to generalize.\n",
    "\n",
    "\n",
    "*Interestinly enough, these assumptions rarely hold in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp = pd.DataFrame( [[len(train_df), len(train_df.dropna(axis=0))]], columns=['Original', 'Full Values'] ) \n",
    "df_comp.plot.bar(width=0.5, figsize=(6,5), title=\"DataFrame Sizes with / without Missing Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What if we only drop the top 5\n",
    "\n",
    "_Note:_ The number 5 is arbitrarily chosen here. \n",
    "\n",
    "See the documentation here: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = train_df.copy()\n",
    "\n",
    "dfSizes = [ len(train_df) ]  # The original dataframe size\n",
    "columnNames = [ 'Original' ]\n",
    "\n",
    "# Iterate over the top-5 features with the most missing values and drop any row that contains them\n",
    "for featName in empty_fractions.sort_values(ascending=False).head().index:\n",
    "\n",
    "    # The subset parameter allows us to check in specific features\n",
    "    df_copy = df_copy.dropna( subset=[featName], axis=0 )\n",
    "\n",
    "    dfSizes.append(len(df_copy))\n",
    "    columnNames.append( '-%d Feats' % (len(dfSizes)-1) )\n",
    "\n",
    "# In the end, append the size of the dataframe where we have dropped everything\n",
    "dfSizes.append( len(train_df.dropna(axis=0)) )\n",
    "columnNames.append( 'Full Values' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp = pd.DataFrame( [dfSizes], columns=columnNames ) \n",
    "df_comp.plot.bar(width=0.5, figsize=(6,5), title=\"DataFrame Sizes with / without Missing Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 2: Drop the Features\n",
    "\n",
    "From the previous brief analysis, if we drop _all_ rows that have at least one missing value, then we are removing _a lot_ of information! We see, for instance, that the \"NUMCHLD\" feature has plenty of missing values and results in a significant reduction of our dataset.\n",
    "\n",
    "Here's an alternative that preserves more information in this situation. Instead of droping the _rows_ that have an empty value, we can simply drop the column that has the missing data. It will remove a lot less information.\n",
    "\n",
    "We will _still_ lose _some_ information, but not as much as before. Let's see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the feature NUMCHLD\n",
    "no_numchld_df = train_df.drop( ['NUMCHLD'], axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a copy to work with\n",
    "df_copy = no_numchld_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the percentage of missing values for each column in the new dataframe (without the NUMCHLD feature)\n",
    "empty_fractions = 100.0 * (df_copy.isnull().sum() / len(df_copy))\n",
    "empty_fractions.sort_values(ascending=True).plot(kind=\"barh\", figsize=(6,5))\n",
    "\n",
    "average_overall = empty_fractions.mean()\n",
    "plt.axvline(x=average_overall, color='red')  # Plots a vertical line at x = <value>\n",
    "plt.text(average_overall - 1.5, -2, 'average\\nmissing', rotation=90)  # Set the text for the tick\n",
    "\n",
    "plt.title(\"Fraction of Instances with Missing Values per Feature\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSizes = [ len(train_df), len(df_copy) ]\n",
    "columnNames = [ 'Original', 'No NUMCHLD' ]\n",
    "\n",
    "# Iterate over the top-5 features with the most missing values and drop any row that contains them\n",
    "for featName in empty_fractions.sort_values(ascending=False).head().index:\n",
    "\n",
    "    # The subset parameter allows us to check in specific features\n",
    "    df_copy = df_copy.dropna( subset=[featName], axis=0 )\n",
    "\n",
    "    dfSizes.append(len(df_copy))\n",
    "    columnNames.append( '-%d Feats' % (len(dfSizes)-2) )\n",
    "\n",
    "# In the end, append the size of the dataframe where we have dropped everything\n",
    "dfSizes.append( len(df_copy.dropna(axis=0)) )\n",
    "columnNames.append( 'Full Values' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp = pd.DataFrame( [dfSizes], columns=columnNames ) \n",
    "df_comp.plot.bar(width=0.5, figsize=(6,5), title=\"DataFrame Sizes with / without Missing Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not ideal, but still better than the previous case!\n",
    "\n",
    "Notice that if we now remove the _rows_ that have missing data, we end up with just shy of 7500 instances, much better compared to the ~1200-1300 instances of the previous case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could keep doing the same thing with the other columns, removing one of them at a time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's compare the two models\n",
    "\n",
    "Since our goal is to predict new instances, we would like to know how each approach performs as part of a training procedure.\n",
    "\n",
    "Here's what we will do:\n",
    "\n",
    "1. We will use the _original_ data frame and drop all the instances that have at least one missing value. We will then train a model on the remaining data.\n",
    "\n",
    "1. We will use the data frame where we have first dropped the NUMCHLD feature. Following this step, we will drop all instances that have at least one missing value. We will build our classifier on the remaining data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the first dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dataframe 1: drop all instances with missing values\n",
    "listwise_delete_df = train_df.dropna()\n",
    "\n",
    "# Get the features of this \n",
    "listDelFeats = listwise_delete_df.drop( ['TARGET_B'], axis=1 )\n",
    "listDelLabels = listwise_delete_df[['TARGET_B' ]]\n",
    "\n",
    "listDelFeats = pd.get_dummies(listDelFeats)\n",
    "\n",
    "logReg = LogisticRegression(C=1, solver='lbfgs')\n",
    "listDelAvgPrec = np.mean(cross_val_score(logReg, listDelFeats, listDelLabels, scoring='roc_auc', cv=10))\n",
    "print(listDelAvgPrec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the second dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dataframe 2: drop all instances with missing values\n",
    "no_feat_numchld = train_df.drop( ['NUMCHLD'], axis=1 ).dropna()\n",
    "\n",
    "# Get the features of this \n",
    "noNumChldFeats = no_feat_numchld.drop( ['TARGET_B'], axis=1 )\n",
    "noNumChldLabels = no_feat_numchld[['TARGET_B' ]]\n",
    "\n",
    "noNumChldFeats = pd.get_dummies(noNumChldFeats)\n",
    "\n",
    "logReg = LogisticRegression(C=1, solver='lbfgs')\n",
    "noNumChldAvgPrec = np.mean(cross_val_score(logReg, noNumChldFeats, noNumChldLabels, scoring='roc_auc', cv=10))\n",
    "print(noNumChldAvgPrec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 3: Impute with a constant value\n",
    "\n",
    "Another popular and very simple approach to address the issue is to impute with a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dataframe 3: drop all instances with missing values\n",
    "zeroValuedDf = train_df.fillna( 0 )\n",
    "\n",
    "# Get the features of this \n",
    "zeroValuedFeats = zeroValuedDf.drop( ['TARGET_B'], axis=1 )\n",
    "zeroValuedLabels = zeroValuedDf[['TARGET_B' ]]\n",
    "\n",
    "zeroValuedFeats = pd.get_dummies(zeroValuedFeats)\n",
    "\n",
    "logReg = LogisticRegression(C=1, solver='lbfgs')\n",
    "zeroValuedAvgPrec = np.mean(cross_val_score(logReg, zeroValuedFeats, zeroValuedLabels, scoring='roc_auc', cv=10))\n",
    "print(zeroValuedAvgPrec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 4: Impute with the average value of the dataframe\n",
    "\n",
    "A slightly better approach compared to the previous one is to use a more \"data driven\" value. Instead of arbitrarily imputing missing values with zeros, we can impute missing values with the _average value_ of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Your code here for imputation\n",
    "\n",
    "\n",
    "# Remember to evaluate your model!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 5: Masking the missing value\n",
    "\n",
    "An even more involved approach is to create a _new feature_ that will tell us if the original value is missing or not (binary feature). We can then impute the missing value with one of the previous approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Your code here for imputation\n",
    "\n",
    "\n",
    "# Remember to evaluate your model!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
