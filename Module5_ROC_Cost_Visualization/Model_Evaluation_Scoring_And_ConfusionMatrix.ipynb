{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining for Business Analytics\n",
    "\n",
    "## Model Evaluation Measures \n",
    "\n",
    "Spring 2019 - Prof. George Valkanas\n",
    "\n",
    "Material based on content courtesy of Prof. Foster Provost\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all of the packages we will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries we will be using\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = 10, 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have already seen a measure to evaluate the performance / effectiveness of a data mining model: **accuracy**. \n",
    "\n",
    "<table>\n",
    "    <tr style=\"font-size: large; font-weight: bold; background-color: light-gray\">\n",
    "        <td style=\"border: 2px solid black\"> ID </td> \n",
    "        <td style=\"border: 2px solid black\"> True Label </td> \n",
    "        <td style=\"border: 2px solid black\"> Predicted Label </td>\n",
    "    </tr>\n",
    "    <tr style=\"background-color: lightgreen\">\n",
    "        <td style=\"border: 2px solid black\"> 1 </td> <td> 1 </td> <td style=\"border: 2px solid black\"> 1 </td>\n",
    "    </tr>\n",
    "    <tr style=\"background-color: lightgreen; border: 2px solid black\">\n",
    "        <td style=\"border: 2px solid black\"> 2 </td> <td> 1 </td> <td style=\"border: 2px solid black\"> 1 </td>\n",
    "    </tr>\n",
    "    <tr style=\"background-color: lightgreen; border: 2px solid black\">\n",
    "        <td style=\"border: 2px solid black\"> 3 </td> <td> 0 </td> <td style=\"border: 2px solid black\"> 0 </td>\n",
    "    </tr>\n",
    "    <tr style=\"background-color: tomato; border: 2px solid black\">\n",
    "        <td style=\"border: 2px solid black\"> 4 </td> <td> 0 </td> <td style=\"border: 2px solid black\"> 1 </td>\n",
    "    </tr>\n",
    "    <tr style=\"background-color: lightgreen; border: 2px solid black\">\n",
    "        <td style=\"border: 2px solid black\"> 5 </td> <td> 0 </td> <td style=\"border: 2px solid black\"> 0 </td>\n",
    "    </tr>\n",
    "    <tr style=\"background-color: lightgreen; border: 2px solid black\">\n",
    "        <td style=\"border: 2px solid black\"> 6 </td> <td> 1 </td> <td style=\"border: 2px solid black\"> 1 </td>\n",
    "    </tr>\n",
    "    <tr style=\"background-color: tomato; border: 2px solid black\">\n",
    "        <td style=\"border: 2px solid black\"> 7 </td> <td> 1 </td> <td style=\"border: 2px solid black\"> 0 </td>\n",
    "    </tr>\n",
    "    <tr style=\"background-color: tomato; border: 2px solid black\">\n",
    "        <td style=\"border: 2px solid black\"> 8 </td> <td> 1 </td> <td style=\"border: 2px solid black\"> 0 </td>\n",
    "    </tr>\n",
    "    <tr style=\"background-color: lightgreen; border: 2px solid black\">\n",
    "        <td style=\"border: 2px solid black\"> 9 </td> <td> 0 </td> <td style=\"border: 2px solid black\"> 0 </td>\n",
    "    </tr>\n",
    "    <tr style=\"background-color: tomato; border: 2px solid black\">\n",
    "        <td style=\"border: 2px solid black\"> 10 </td> <td> 0 </td> <td style=\"border: 2px solid black\"> 1 </td>\n",
    "    </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It may take us a while to digest the information in the above table, not to mention to use it and actually evaluate the model in question; and it's only 10 rows! Instead, a more aggregate view of that information would be incredibly useful.\n",
    "\n",
    "However, we want to maintain all of the important information that is available there. Accuracy captures only part of it, because it tells us only how many things were correctly classified.  Even then, things are lumped together, as we consider cases of \"1\" and cases of \"0\" to be equally important.  For similar reasons, we would like to know how many of the _misclassified_ instances truly belong to class \"0\" or to class \"1\".  Accuracy doesn't answer that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Confusion Matrix\n",
    "\n",
    "A succinct version of the previous information is given by a **confusion matrix**.  For a _binary_ classification problem, the confusion matrix has a 2x2 layout. A visual diagram of what \n",
    "\n",
    "\n",
    "<table style=\"border: 0px\">\n",
    "    <tr style=\"border: 0px\">\n",
    "        <td style=\"width: 60%; text-align: justify\">\n",
    "<table width=\"100%\">\n",
    "    <tbody>\n",
    "        <tr style=\"background: rgba(255, 255, 255, 0.1)\">\n",
    "            <td colspan=\"2\" width=\"30%\"></td>\n",
    "            <td colspan=\"2\" style=\"border: 2px solid black; background: white; text-align: center\" ><b>True Class</b></td>\n",
    "        </tr>\n",
    "        <tr style=\"background: rgba(255, 255, 255, 0.1)\">\n",
    "            <td colspan=\"2\"></td>\n",
    "            <td style=\"border: 2px solid black; background: #E8E8E8; text-align: center\"><b>Positive (1)</b></td>\n",
    "            <td style=\"border: 2px solid black; background: #E8E8E8; text-align: center\"><b>Negative (0)</b></td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td rowspan=\"2\" style=\"border: 2px solid black; background: white; text-align: center\"><b>Predicted<br/>Class</b></td>\n",
    "            <td style=\"border: 2px solid black; background: #E8E8E8; text-align: center\"><b>Positive<br/>(\"Yes\")</b></td>\n",
    "            <td style=\"border: 2px solid black; background: lightgreen; text-align: center\">\n",
    "                <b>True Positive (TP)</b>\n",
    "            </td>\n",
    "            <td style=\"border: 2px solid black; background: #ff9999; text-align: center\">\n",
    "                <b>False Positive (FP)</b>\n",
    "            </td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"border: 2px solid black; background: #E8E8E8; text-align: center; text-align: center\">\n",
    "                <b>Negative<br/>(\"No\")</b>\n",
    "            </td>\n",
    "            <td style=\"background: #ff9999; border: 2px solid black; text-align: center\">\n",
    "                <b>False Negative (FN)</b>\n",
    "            </td>\n",
    "            <td style=\"background: lightgreen; border: 2px solid black; text-align: center\">\n",
    "                <b>True Negative (TN)</b>\n",
    "            </td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>\n",
    "            <span style=\"display: block; text-align: center\">\n",
    "                <b><br/>Confusion Matrix</b>\n",
    "            </span>\n",
    "        </td>\n",
    "        <td style=\"border: 0px; width: 5%\"></td>\n",
    "        <td style=\"display: block; text-align: justify\">\n",
    "            <img src=\"images/Precisionrecall.svg.png\" height=75% width=75% /> <br/>\n",
    "            <span style=\"display: block; text-align: center\">\n",
    "                <b>Visual Representation of a Confusion Matrix</b>\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "Original <a href=\"https://en.wikipedia.org/wiki/Precision_and_recall\">Image source</a>\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the confusion matrix, we can compute several other measures. For example:\n",
    "\n",
    "$$accuracy = \\frac{TP + TN}{TP + FP + FN + TN} $$\n",
    "\n",
    "and\n",
    "\n",
    "$$precision = \\frac{TP}{TP + FP}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important and overlooked (always remember this!)\n",
    "\n",
    "The values of a confusion matrix are computed according to the predicted _class_ of a model, _not_ its probability. Therefore, a confusion matrix is defined with respect to a **classifier**, not a scoring model (e.g., a class-probability estimation model).  Our models *are* scoring models!\n",
    "\n",
    "We will return to this point later on.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how we can compute a Confusion Matrix in Python. We've had enough of toy examples and \"random\" datasets. Let's use a real dataset this time!\n",
    "\n",
    "\n",
    "We're going to use a mail response data set from a real direct marketing campaign. The dataset is located in `data/mailing.csv`. Each record represents an individual who was targeted with a direct marketing offer.  The offer was a solicitation to make a charitable donation. \n",
    "\n",
    "The columns (features) are:\n",
    "\n",
    "```\n",
    "income       household income\n",
    "Firstdate    data assoc. with the first gift by this individual\n",
    "Lastdate     data associated with the most recent gift \n",
    "Amount       average amount by this individual over all periods (incl. zeros)\n",
    "rfaf2        frequency code\n",
    "rfaa2        donation amount code\n",
    "pepstrfl     flag indicating a star donator\n",
    "glast        amount of last gift\n",
    "gavr         amount of average gift\n",
    "```\n",
    "\n",
    "The target variables is `class` and is equal to `1` if they gave to this campaign and `0` otherwise.\n",
    "\n",
    "Let's first read the data and see what a few entries contain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = pd.read_csv(\"data/mailing.csv\")  # Load the data\n",
    "original.head()  # Let's take a look at the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the description above, and the head of the data, we see that two of the fields are **categorical** (text) instead of the typical **numerical** fields we have been looking at until this point. Today, one of the models we will be using is a logistic regression. From the previous classes, we have seen that logistic regression requires *all* fields to be numerical. To do this, we are going to create \"dummy\" variables for all the fields that are categorical.\n",
    "\n",
    "#### Dummyize\n",
    "A dummy variable is a binary variable corresponding to one value of a categorical variable.\n",
    "The typical way to create dummies for a field is to create new variables for each possible category of the field. For example consider a field called color that can have the possible values \"red\", \"blue\", and \"green\". To dummyize color, we would create three new features: \"color_red\", \"color_blue\", and \"color_green\". These fields would take the value 1 or 0 depending on the actual value of color. Each record can only have one of these fields set to 1!\n",
    "\n",
    "Notes:\n",
    "\n",
    "- You can also leave out one of the possible categories. For example, in the above example that had three possible values, you can create only two dummies. This, because when \"color_red\"=0 and \"color_blue\"=0 it means that \"color_green=1\".  Often all three dummies are created anyway; it is slightly redundant, but makes the models more comprehensible.\n",
    "\n",
    "- There also are cases where non-numeric variables can take on multiple values (for example, `colors = {red, white, blue}`).  In these cases again often binary variables are created for each value, the obvious difference being that now more than one can be non-zero (and you would need to represent all the values).\n",
    " \n",
    "\n",
    "So.  Let's dummyize the fields `rfaa2` and `pepstrfl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = original.copy()\n",
    "for field in ['rfaa2', 'pepstrfl']:  # Do the same thing for the two fields of interest\n",
    "    # Go through each possible value \n",
    "    for value in data[field].unique():\n",
    "        # Create a new binary field\n",
    "        data[field + \"_\" + value] = pd.Series(data[field] == value, dtype=int)\n",
    "\n",
    "    # Drop the original field\n",
    "    data = data.drop([field], axis=1)\n",
    "    \n",
    "# Let's look at the data again, after the modifications\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use part of our dataset for training and the rest of it for testing. Because we are doing this for illustration purposes, we will do a simple split of the data ourselves. However, when doing this we should be using a more robust methodological approach (which would that be?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The \"data\" dataframe contains everything together.\n",
    "# Get the features separately from the class.\n",
    "X = data.drop(['class'], axis=1)\n",
    "Y = data['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep 75% of the data for training and 25% for testing. We have used this method before.\n",
    "X_mailing_train, X_mailing_test, Y_mailing_train, Y_mailing_test = train_test_split(X, Y, train_size=.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's train a Logistic Regression model on our training set\n",
    "model_mailing = LogisticRegression(C=1000000)   # Remember what a large C value means!!!\n",
    "model_mailing.fit(X_mailing_train, Y_mailing_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the trained model on the testing dataset and get the predicted classes\n",
    "predictions = model_mailing.predict(X_mailing_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create our confusion matrix. To do that we need:\n",
    "1. The predicted class for each instance in the test set\n",
    "1. The true class for each instance in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's compute the confusion matrix first.\n",
    "# To do that we need the actual classes and the predicted ones\n",
    "conf_mtx = metrics.confusion_matrix(Y_mailing_test, predictions, labels=[1, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's turn the confusion matrix into a DataFrame, to make it more presentable\n",
    "conf_mtx_df = pd.DataFrame(conf_mtx.T, columns=['(True) p', '(True) n'], index=['[Predicted] Y', '[Predicted] N'])\n",
    "conf_mtx_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1:** What do you think? Looking at the confusion matrix above, is that a good model?\n",
    "\n",
    "**Question 2:** What do you expect if you decrease the value for `C` above ?\n",
    "\n",
    "**Task 1:** Try the same with a Decision Tree, with a maximum depth of your choice. What does your confusion matrix look like? What do you think about the resulting model?\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Scoring Model\n",
    "\n",
    "As previously stated, our models are _scoring_ models. That means that they produce a value reflecting the class-probability estimation. In our code above, instead of the probability estimation, we asked directly for the _most probable_ class. In practical applications this isn't very useful or meaningful, for a number of reasons, and our previous example demonstrates how such an approach can fail spectacularly.\n",
    "\n",
    "So, what can we do? In reality, we use the probability estimates _directly_. We've used code that does that: the probabilistic decision surfaces!\n",
    "\n",
    "The piece of code below shows how we compute the class probability for each of the _testing_ instances, using a trained model. We will use a logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get probabilities that an item belongs to class=1\n",
    "probabilities = model_mailing.predict_proba(X_mailing_test)[:, 1]\n",
    "\n",
    "# Print the probabilities, just to see some examples\n",
    "probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see what the distribution of those probabilities are\n",
    "plt.figure()\n",
    "plt.hist(probabilities, bins=15, range=(min(probabilities), max(probabilities)), log=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are pretty low probabilities, well below an \"expected\" 0.5 value ! It makes sense then that practically everything was classified as 0!\n",
    "\n",
    "**Question:** How do you think that we should fix that?\n",
    "***\n",
    "\n",
    "Well, instead of relying on a threshold defined by the Python package (or other means), let's use our own! Then an instance with a probability estimate greater than our threshold will be marked as \"positive\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *We* get to choose the value\n",
    "threshold = 0.08\n",
    "\n",
    "# The `probabilities` variable is of np.array type.\n",
    "# Anything above the threshold belongs to class 1, otherwise to class 0\n",
    "thresh_predictions = (probabilities > threshold).astype(int)\n",
    "\n",
    "# Let's print the predictions again\n",
    "thresh_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the confusion matrix with the thresholded predictions!\n",
    "conf_mtx = metrics.confusion_matrix(Y_mailing_test, thresh_predictions, labels=[1, 0])\n",
    "\n",
    "# Like before, once we have the matrix, we convert it to a dataframe for a nicer visualization\n",
    "conf_mtx_df = pd.DataFrame(conf_mtx.T, columns=['(True) p', '(True) n'], index=['[Predicted] Y', '[Predicted] N'])\n",
    "conf_mtx_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1:** What is the accuracy for this threshold?\n",
    "\n",
    "**Question 2:** Is this good performance? Is it _better_ than before?\n",
    "\n",
    "**Question 3:** Is that the _right_ threshold? How can we tell?\n",
    "\n",
    "**Task 1:** Play around with the threshold value and see what the confusion matrix is.\n",
    "\n",
    "**Task 2:** Redo the process, but use a Decision Tree Classifier. How do the values look in that case for different thresholds?\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important and overlooked (cont'd)\n",
    "\n",
    "From the previous discussion it is clear that, actually, we can use our scoring models to create confusion matrices, _as long as_ we use a *threshold* on the score! This approach allows for great flexibility.\n",
    "\n",
    "The threshold should be chosen _carefully_, and **with the business need in mind**.  For binary classification problems, most modeling programs use a default threshold of _0.5_ on the predicted class probability estimate.   This is because the modeling program does not know the business setting, and 0.5 makes sense as a default (in expectation it gives the maximum classification accuracy, if the probabilities are well calibrated).\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expanding on the single threshold idea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the previous tasks was to \"play around\" with the threshold and see the resulting confusion matrix.  As fun as this may be, it is impractical in real life scenarios.  We would like something more automated than that.\n",
    "\n",
    "**Question:** Can you think of a way to \"automate\" this thresholding idea? (Hint: _When_ do you expect the values of the confusion matrix to change? )\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with a simpler approach first, to illustrate some basic points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's train our model on the *training data*\n",
    "model_mailing = LogisticRegression(C=10)\n",
    "model_mailing.fit(X_mailing_train, Y_mailing_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get the probabilities once more\n",
    "probabilities = model_mailing.predict_proba(X_mailing_test)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The built-in Python zip method: https://www.programiz.com/python-programming/methods/built-in/zip\n",
    "\n",
    "# Let's show the PROBABILITY alongside to the PREDICTED class\n",
    "logRegDf = pd.DataFrame(list(zip(probabilities, Y_mailing_test)), columns=[\"PROBABILITY\", \"TRUE_CLASS\"])\n",
    "logRegDf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probability values are _unordered_. We must sort them first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logReg_SortedProb = logRegDf.sort_values(by=['PROBABILITY'], ascending=False)\n",
    "logReg_SortedProb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logReg_SortedProb[\"CUMUL_CORRECT\"] = logReg_SortedProb[\"TRUE_CLASS\"].cumsum()\n",
    "logReg_SortedProb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On the y-axis we want to plot our cumulative correct response\n",
    "yAxisCumul = logReg_SortedProb[\"CUMUL_CORRECT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.plot(range(0, len(yAxisCumul)), yAxisCumul, label=\"Logistic Regression\")\n",
    "plt.plot([0, len(yAxisCumul)], [0, yAxisCumul.max()], 'k--', label=\"Random\")  # This creates a LINE\n",
    "plt.xlabel(\"Test instances targeted (decreasing score)\")\n",
    "plt.ylabel(\"Number of positives targeted\")\n",
    "plt.title(\"Cumulative response curve\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of duplicating code, let's create a simple method that trains a model with the correct info and computes the CRC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Let's create a method that trains and returns the CRC of a clasifier\n",
    "\n",
    "def train_and_compute_crc( model, x_train, y_train, x_test, y_test):\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    # Let's get the probabilities. FOCUS ON THE POSITIVE CLASS\n",
    "    probabilities = model.predict_proba(x_test)[:, 1]\n",
    "\n",
    "    # Create a dataframe that we can conveniently manipulate\n",
    "    model_df = pd.DataFrame(list(zip(probabilities, y_test)), columns=[\"PROBABILITY\", \"TRUE_CLASS\"])\n",
    "\n",
    "    # Sort the dataframe rows by the PROBABILITY\n",
    "    model_df_sorted = model_df.sort_values(by=['PROBABILITY'], ascending=False)\n",
    "\n",
    "    # Compute the CUMULATIVE correct responses up until the\n",
    "    return model_df_sorted[\"TRUE_CLASS\"].cumsum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's train a Logistic Regression classifier\n",
    "model = LogisticRegression(C=1)\n",
    "logReg_crc = train_and_compute_crc( model, X_mailing_train, Y_mailing_train, X_mailing_test, Y_mailing_test )\n",
    "\n",
    "# Let's train a Decision Tree Classifier\n",
    "model = DecisionTreeClassifier(criterion='entropy', max_depth=15)\n",
    "dec_tree_crc = train_and_compute_crc( model, X_mailing_train, Y_mailing_train, X_mailing_test, Y_mailing_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot the above results, together\n",
    "plt.plot(range(0, len(dec_tree_crc)), dec_tree_crc, label=\"Decision Tree\")\n",
    "plt.plot(range(0, len(logReg_crc)), logReg_crc, label=\"Logistic Regression\")\n",
    "plt.plot([0,len(logReg_crc)], [0,max(logReg_crc)], 'k--', label=\"Random\")\n",
    "plt.xlabel(\"Number of test instances targeted (decreasing score)\")\n",
    "plt.ylabel(\"Number of positives targeted\")\n",
    "plt.title(\"Cumulative response curve\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:**\n",
    "\n",
    "You can actually generate a Cumulative Response Curve (CRC) for Cross Validation !!! How crazy is that !? It is _very_ good practice to try and do this.\n",
    "\n",
    "(Yes, it is not obvious and will take time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
