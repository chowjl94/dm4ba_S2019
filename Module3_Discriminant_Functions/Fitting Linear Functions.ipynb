{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining for Business Analytics\n",
    "## Discriminant Functions\n",
    "\n",
    "Spring 2019 - Prof. George Valkanas\n",
    "\n",
    "Material based on content courtesy of Prof. Foster Provost\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading & Installing Packages\n",
    "There are some packages that will be required for this assignment that are no pre-loaded into Jupyter hub. You can install them following the instructions below.\n",
    "\n",
    "Enter the following commands into jupyter's terminal one at a time:\n",
    "```\n",
    "sudo pip install liac-arff\n",
    "sudo apt install graphviz\n",
    "sudo pip install graphviz\n",
    "sudo pip install pydotplus\n",
    "```\n",
    "enter \"`Y`\" when promted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scripts and Data\n",
    "\n",
    "In addition to Python Notebooks, we often write our code in Python scripts.  These are separate files, where we typically include things that we want to reuse very often, not just within the Notebook itself.  We can use them as part of other work that we may be doing (e.g., during deployment) or reference them from multiple notebooks.  That way the code doesn't clutter up the notebook and in case we have a fix for a problem in the code, then we don't need to change it in many places!\n",
    "\n",
    "We import and use these scripts in our code just like we do with any other Python module (e.g., Pandas). Basically, we don't care about seeing the actual code of these functions, as long as they work correctly.  All that we need to know / remember / understand is their functionality, i.e., what we need to pass as input and what they return as output.\n",
    "\n",
    "Take a look at the following:\n",
    "\n",
    "* We use the folder **_dstools_** that is in the same directory (folder) as this notebook\n",
    "* We import the file: **data\\_tools**\n",
    "\n",
    "This file is a   \".py\" which has Python commands and functions, such as:\n",
    "\n",
    "1. Decision_Surface -- this is the function that visualizes the segmentation of the learned model\n",
    "2. Color_Data_Points -- this creates the artificial data set, for us to experiment with\n",
    "\n",
    "After the \"import\" we can use these 3 functions, just like we use pre-defined packages like Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries we will be using\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd # importing cuteness\n",
    "\n",
    "# Importing the modules from SKLEARN that we are going to use today\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn import datasets\n",
    "\n",
    "from dstools import data_tools\n",
    "\n",
    "\n",
    "# for plotting\n",
    "from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "import pydotplus\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = 14, 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data & Functions\n",
    "Let's revisit briefly the dataset that we used previously. It's a 2D dataset, representing customers that we reached out in the past with an ad-campaign. For each customer, we know their age and the number of years as a customer (when we ran the ad)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the randomness\n",
    "np.random.seed(36)\n",
    "\n",
    "# Number of users, i.e. number of instances in our dataset\n",
    "n_users = 500\n",
    "\n",
    "# Features that we know about each user. The attributes below are for illustration purposes only!\n",
    "variable_names = [\"name\", \"age\", \"years_customer\"]\n",
    "variables_keep = [\"years_customer\", \"age\"]\n",
    "target_name = \"response\"\n",
    "\n",
    "# Generate data with the \"datasets\" function from SKLEARN (package)\n",
    "# This function returns two variables: predictors and target\n",
    "\n",
    "predictors, target = datasets.make_classification(n_features=3, n_redundant=0, \n",
    "                                                  n_informative=2, n_clusters_per_class=2,\n",
    "                                                  n_samples=n_users)\n",
    "\n",
    "# We will write this data in a dataframe (pandas package)\n",
    "\n",
    "data = pd.DataFrame(predictors, columns=variable_names)\n",
    "\n",
    "# We want to take each column of the dataframe to change the values \n",
    "\n",
    "data['age'] = data['age'] * 10 + 50\n",
    "data['years_customer'] = (data['years_customer'] + 6)/2\n",
    "data[target_name] = target\n",
    "\n",
    "# Our variables (features) will be stored in one variable called X\n",
    "X = data[variables_keep]\n",
    "\n",
    "# Our target will be stored in one variable called Y\n",
    "Y = data[target_name]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just to see how the responses are distributed\n",
    "data.groupby(\"response\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's visualize the dataset to remember it\n",
    "plt.figure(figsize=[7,6])\n",
    "data_tools.Decision_Surface(X, Y, model=None, probabilities=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at our data one more time by projecting them on the `years_customer` feature, which we've established looks like a better way to separate them. In fact, let's put everything on a single line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the best feature here after looking at the data above\n",
    "best_feat = 'years_customer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Specify the color for each data point, based on the response\n",
    "color = data_tools.Color_Data_Points(data[\"response\"])\n",
    "\n",
    "\n",
    "# Select all of the rows / records that have a positive response.\n",
    "# The result of the right hand side is a DataFrame\n",
    "negat_response = data.loc[data[\"response\"] == 0]\n",
    "posit_response = data.loc[data[\"response\"] == 1]\n",
    "\n",
    "# Minimum and maximum value for the best performing feature\n",
    "bfeat_value_range = (X[best_feat].min(), X[best_feat].max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import NullFormatter\n",
    "plt.rcParams['figure.figsize'] = [15.0, 2.0]\n",
    "\n",
    "# This formatter will change the appearance of the ticks on the x-axes\n",
    "noTicksFmtr = NullFormatter()\n",
    "\n",
    "# Specifying the size (and partly, the location) of the canvas area for the distribution\n",
    "hist_height = 0.3\n",
    "hist_gap = 0.2\n",
    "\n",
    "\n",
    "# Method that creates a particular histogram plot\n",
    "def create_hist_plot( canvas_size, bfeat_value_range, plot_data, color ):\n",
    "    bounds_plot = plt.axes( canvas_size )\n",
    "    bounds_plot.xaxis.set_major_formatter(noTicksFmtr)\n",
    "    bounds_plot.xaxis.set_major_formatter(noTicksFmtr)\n",
    "    bounds_plot.set_xlim(bfeat_value_range)\n",
    "    bounds_plot.hist( plot_data, color=color, alpha=0.6, bins=30)\n",
    "    return bounds_plot\n",
    "\n",
    "\n",
    "rect_histx = plt.axes()\n",
    "rect_histx.scatter(X[best_feat], Y, c=color, s=50)\n",
    "bounds = rect_histx.get_position().bounds\n",
    "\n",
    "\n",
    "# Compute the bounds for the histogram that is ABOVE. Plot it\n",
    "hist_canvas = [ bounds[0], bounds[1] + bounds[3] + hist_gap, bounds[2], hist_height ]\n",
    "hist_plot = create_hist_plot(hist_canvas, bfeat_value_range, posit_response[best_feat], 'b')\n",
    "\n",
    "\n",
    "# Compute the bounds for the histogram that is Below. Plot it\n",
    "hist_canvas = [ bounds[0], bounds[1] - (hist_gap + hist_height), bounds[2], hist_height ]\n",
    "hist_plot = create_hist_plot(hist_canvas, bfeat_value_range, negat_response[best_feat], 'r')\n",
    "hist_plot.invert_yaxis()  # Turn the historgam upside down\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear discriminant models\n",
    "\n",
    "Instead of doing the whole \"entropy and the information gain\" thing, one could argue that the data exhibit a nice-looking linear relation. The greater the value for our best performing feature, the more likely they will respond (`y=1`). The lower the value, the less likely (`y=0`).\n",
    "\n",
    "\n",
    "Following the above rationale, we can build a linear model that will help us separate the two classes. The simplest linear model that we know is linear regression, which looks like this:\n",
    "\n",
    "$$ f({\\bf x}) = y = b + a_1 x_1 + a_2 x_2 + a_3 x_3 + ... $$\n",
    "\n",
    "\n",
    "Looking at the data (see scatterplot above), can you estimate by eye where a good linear discriminant would be?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are looking for a linear discriminant, an immediate thought is to use linear regression. Let's do that now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_linreg_model(x_feats, y, title=''):\n",
    "    \n",
    "    # Let's learn a LINEAR regression model\n",
    "    model_lin = LinearRegression()\n",
    "    model_lin.fit(x_feats, y)\n",
    "\n",
    "    y_lin = model_lin.predict(x_feats)\n",
    "\n",
    "    plt.plot(x_feats, y_lin, 'orange')  # If you cannot see the orange lines, change the color to 'black'\n",
    "    plt.scatter(x_feats, y, c=color)\n",
    "    plt.title(\"Linear Regression fit\" + title)\n",
    "    return\n",
    "\n",
    "\n",
    "plt.figure(figsize=[11,4])\n",
    "\n",
    "# Create a linear regression model for the \"age\"\n",
    "plt.subplot(1, 2, 1)\n",
    "plot_linreg_model( X['age'].values.reshape(-1, 1), Y.values.reshape(-1, 1), title=' (Age)' )\n",
    "\n",
    "# Create a linear regression model for the \"years_customer\"\n",
    "plt.subplot(1, 2, 2)\n",
    "plot_linreg_model( X['years_customer'].values.reshape(-1, 1), Y.values.reshape(-1, 1), title=' (Years Customer)' )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1:** Does this look correct? Why? Why not?\n",
    "\n",
    "**Question 2:** Can we somehow _recast_ what we are trying to compute?\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression\n",
    "Linear regression is a great tool, but doesn't fit our purpose. In situations like this, instead, we use what is called **Logistic Regression**.\n",
    "\n",
    "Logistic Regression is used to quantify the _probability_ that an instance **x** belongs to a particular class. The Logistic Regression model recasts the original linear equation and solves the following:\n",
    "\n",
    "$$\\log \\frac{p_c({\\bf x})}{1 - p_c({\\bf x})} = f({\\bf x}) = w_0 + w_1*x_1 + w_2*x_2 + \\dots $$\n",
    "\n",
    "where $p_c({\\bf x})$ refers to the probability that instance ${\\bf x}$ belongs to the target class of interest $c$. This is the **log-odds** linear function.\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "\n",
    "**Question 1:** What is the model that we learn here?\n",
    "\n",
    "\n",
    "**Question 2:** What is the target class of _interest_ in our example?\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we build and visualize a **Logistic regression** model. You can also find logistic regression modeling in the sklearn package.\n",
    "\n",
    "To get a better comparative sense with linear regression, we show the two models side by side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_logreg_model(x_feats, y, title=''):\n",
    "    \n",
    "    # Let's learn a LINEAR regression model\n",
    "    model_log = LogisticRegression(solver='lbfgs')\n",
    "    model_log.fit(x_feats, y)\n",
    "\n",
    "    y_hat = model_log.predict_proba(x_feats)[:,1]\n",
    "\n",
    "    plt.scatter(x_feats, y, c=color)\n",
    "    plt.scatter(x_feats, y_hat, c='orange')   # If you cannot see the orange lines, change the color to 'black'\n",
    "    plt.title(\"Logistic Regression fit\" + title)\n",
    "    return\n",
    "\n",
    "\n",
    "# Create a plot object that will contain 2 subplots\n",
    "plt.figure(figsize=[11,4])\n",
    "\n",
    "# Generate (and plot) a LINEAR model with our best feature \n",
    "plt.subplot(1, 2, 1)\n",
    "plot_linreg_model( X[best_feat].values.reshape(-1, 1), Y.ravel(), title=' ({})'.format(best_feat) )\n",
    "\n",
    "# Generate (and plot) a LOGISTIC model with our best feature\n",
    "plt.subplot(1, 2, 2)\n",
    "plot_logreg_model( X[best_feat].values.reshape(-1, 1), Y.ravel(), title=' ({})'.format(best_feat) )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Let's create another dataset where we maintain our best performing feature only.\n",
    "# We will do that by copying the existing feature set and setting the value of the poor feature to 0\n",
    "one_feat_df = X.copy()\n",
    "best_feat_index = X.columns.values.tolist().index(best_feat)\n",
    "non_good_feat = X.columns.values.tolist()[1 - best_feat_index]  # Can you see why this works?\n",
    "one_feat_df[non_good_feat] = np.zeros(len(X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's build a logistic regression model using all of our features and show the decision surface\n",
    "\n",
    "# Plot the result\n",
    "plt.figure(figsize=[15,7])\n",
    "\n",
    "\n",
    "# Let's learn a LOGISTIC regression model using the most informative feature\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "model.fit(one_feat_df, Y)\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "# Our method expects a DATAFRAME as X value. This is why we must use the X[['feat']] notation\n",
    "data_tools.Decision_Surface(X, Y, model=model, probabilities=False)\n",
    "plt.title(\"Logistic Regress model (Single Best Feature: {})\".format(best_feat))\n",
    "\n",
    "\n",
    "# Train the model with all the features\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "model.fit(X, Y)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "data_tools.Decision_Surface(X, Y, model=model, probabilities=False)\n",
    "plt.title(\"Logistic Regress model (All Features)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating Probabilities\n",
    "\n",
    "Ok.  For many business problems, we don't need just to estimate the categorical target variable, but we want to estimate the probability that a particular value will be taken.  Just about every classification model can also tell you the estimated probability of class membership.  \n",
    "\n",
    "Let's go back and look at the probabilities estimated by these models. You can visualize the probabilities both for the linear model and the tree-structured model. You can do this by modifying the settings at the top of each code block above **(`show_probabilities = True` or `False`)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's build a logistic regression model using all of our features and show the decision surface\n",
    "\n",
    "# Plot the result\n",
    "plt.figure(figsize=[15,7])\n",
    "\n",
    "\n",
    "# Let's learn a LOGISTIC regression model using the most informative feature\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "model.fit(one_feat_df, Y)\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "# Our method expects a DATAFRAME as X value. This is why we must use the X[['feat']] notation\n",
    "data_tools.Decision_Surface(X, Y, model=model, probabilities=True)\n",
    "plt.title(\"Logistic Regress model (Single Best Feature: {})\".format(best_feat))\n",
    "\n",
    "\n",
    "# Train the model with all the features\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "model.fit(X, Y)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "data_tools.Decision_Surface(X, Y, model=model, probabilities=True)\n",
    "plt.title(\"Logistic Regress model (All Features)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability Estimation and Laplace Correction\n",
    "\n",
    "Let's say that we are working with a Decision Tree classifier, for a binary classification problem (e.g., customer churn). Let's say that for a given instance to predict, we end up in a _leaf node_ with the following information:\n",
    "\n",
    "**Count(** churn=`'yes'` **):** 10\n",
    "\n",
    "**Count(** churn=`'no'` **):** 0\n",
    "\n",
    "\n",
    "#### Question: What is the _probability_ that the customer will leave the service?\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "Remember that our models are learned from data that we have available. The model aims to learn the underlying \"nature\" (read: distribution) of the function / process that generated the data we are working with. Therefore, our **observations** may be incomplete and it's possible that we are missing some data points.\n",
    "\n",
    "Why does this matter? How does this affect probability estimation?\n",
    "\n",
    "$$ p(c) = \\frac{n + 1}{n + m + 2} $$\n",
    "\n",
    "which yields the following probability estimates\n",
    "\n",
    "<img width=\"50%\" src=\"images/laplace_correction.png\"/>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines\n",
    "\n",
    "Support Vector Machines compute the line (or hyper-plane) that best separates the data points which are closest to the **decision boundary**. These data points are called _support vectors_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[8,7])\n",
    "\n",
    "# Let's learn a Linear Support Vector Machine. You can also try an SVC instead of LinearSVC\n",
    "model = svm.LinearSVC(C=0.1, max_iter=100000)  # Try the following model: svm.SVC(gamma='scale', max_iter=100000)\n",
    "model.fit(X, Y)\n",
    "\n",
    "# Our method expects a DATAFRAME as X value. This is why we must use the X[['feat']] notation\n",
    "data_tools.Decision_Surface(X, Y, model=model, probabilities=False)\n",
    "plt.title(\"(Linear) Support Vector Machine model (All Features)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Comprehension Questions\n",
    "\n",
    "**Question 1:** Why do we call it logistic _regression_ although we are clearly using it for classification? Doesn't that contradict our definition of classification?\n",
    "\n",
    "**Question 2:** Intuitively, how would you generate probabilities from a classification tree? From a linear discriminant? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take home question (or in class)\n",
    "##### + 2p credit\n",
    "\n",
    "Combine the code that we have seen here and the code from the Decision Trees notebook and produce plots that show the decision surfaces in a probabilistic manner. Do the same for trees with depth 1, 2, 3, 4 and 5. Each tree will be in its own plot.\n",
    "\n",
    "Instructions for your code\n",
    "* Use the numerical value of your NetID to set the `randomness` \n",
    "* Generate a **single** dataset\n",
    "* Write your code and generate the 5 different plots above.\n",
    "* Save each plot, either manually or programmatically, as `<NetID>_<depth>.jpg` or `<NetID>_<depth>.png`, where `<NetID>` refers to your NetID and `<depth>` refers to the depth of the tree that you are showing. For example, a file with the name `gv760_3.png` is from user gv760 (that's me) and the visualized tree has `depth=3`.\n",
    "* Send both the images and your code (ipython notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
